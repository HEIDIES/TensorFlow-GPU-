显卡资源相关
========
显卡资源(显存，计算力)计算，分配问题
--------
### 先介绍一个实用工具，通过：
    $ pip install gpustat
 进行安装，通过命令：
 
    $ watch --color - n1 gpustat -cpu
 可以对自己的GPU进行实时监控
 ![image](https://github.com/HEIDIES/TensorFlow-GPU-/blob/master/picture-two.png)
 
 ### 显卡资源可以分为显存和浮点整型计算速度，其中GeForce系列以单精度FP32浮点计算为最快，GV100系列优化了半精度FP16浮点运算，该系列显卡的半精度FP16浮点运算远快于单精度FP32运算。
 
 #### 存储资源：FP32占用4个字节，假定我们将权重，偏差，数据特征，数据标签全部以FP32类型存入显存，则一个(Batch_size, Height, Width, Channels)的输入数据一共占用Batch_size * Height * Width * Channels * 4(Bytes)，一个(kernel_size, kernel_size, input_dims, output_dims)的卷积核占用kernel_size * kernel_size * output_dims * 4(Bytes)。当然，不仅如此，每个卷积层的输出的临时特征图也会占用大量显存，为Batch_size * Height * Width * output_dims * 4(Bytes)。而这只是feed_forward过程中的显存占用，如果使用SGD的back_propragation，则需要全部乘以2,如果使用AdamOptimizer，则需要全部乘以4。
 
 #### 计算资源：一层卷积需要Batch_size * Height * Width * kernel_size * kernel_size * input_dims * output_dims / stride次浮点运算，一层全链接需要Batch_size * input_dims * output_dims次浮点运算
